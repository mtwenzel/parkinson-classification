{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://colab.research.google.com/assets/colab-badge.svg\">](https://colab.research.google.com/github/mtwenzel/parkinson-classification/blob/master/PPMI-InceptionV3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying PPMI DAT scans into Parkinson's Disease and Healthy Controls\n",
    "\n",
    "Licensed under [this](LICENSE) license.\n",
    "\n",
    "This notebook shows how we performed the experiment to fine-tune the Inception V3 classifier to distinguish patients with and without signs of Parkinson's disease.\n",
    "\n",
    "The notebook is optimized to work with Google Colab.\n",
    "\n",
    "It is part of the publication \n",
    "> Publication reference and [link](Link) to be inserted after publishing.\n",
    "\n",
    "The data is a derivative of the DAT scans available from the PPMI repository. Roughly, they were processed to represent the central 5 slices of the putamen in one slice by averaging them. The data was then split randomly into a training and a validation set. As we tested the performance on an independant test set drawn from clinical routine which cannot be published, this notebook does not contain testing of the trained classifier.\n",
    "\n",
    "The data as used in the publication can be downloaded here:\n",
    "\n",
    "If you want to run the notebook from Google Colab, put the data into your Google Drive, and adapt the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports. {display-mode:'form'}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Dense,GlobalAveragePooling2D,Flatten,concatenate,BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications import InceptionV3,DenseNet121\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Visualize the Train/Val loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set the data generators. {display-mode:'form'}\n",
    "shear_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "zoom_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "width_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "height_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
    "rotation_range = 10 #@param {type:\"slider\", min:0, max:90, step:5}\n",
    "horizontal_flip = True #@param {type:\"boolean\"}\n",
    "vertical_flip = False #@param {type:\"boolean\"}\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    rotation_range=rotation_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip=vertical_flip) \n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('z:/Data/Parkinson_DATScans UKE/full_ppmi_data/png/all_2d_train', # this is where you specify the path to the main data folder\n",
    "                                                 target_size=(109,91),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=64,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "val_datagen=ImageDataGenerator(rescale=1./255) # No data augmentation here!\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory('z:/Data/Parkinson_DATScans UKE/full_ppmi_data/png/all_2d_val', # this is where you specify the path to the main data folder\n",
    "                                                 target_size=(109,91),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=64,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory('z:/Data/Parkinson_DATScans UKE/Parkinson DAT UKE patients/Markus_Wenzel_UKE/png', # this is where you specify the path to the main data folder\n",
    "                                                 target_size=(109,91),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=566,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=False) # don't shuffle so that the file names and indices are in sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set up the pretrained model, and add dense layers. {display-mode:'form'}\n",
    "\n",
    "first_dense_layer_neurons  = 1024 #@param {type:\"integer\"}\n",
    "second_dense_layer_neurons = 256 #@param {type:\"integer\"}\n",
    "use_global_average_pooling = False #@param {type:\"boolean\"}\n",
    "use_batch_norm             = True #@param {type:\"boolean\"}\n",
    "use_drop_out               = False  #@param {type:\"boolean\"}\n",
    "pretrained_model           = 'inception_v3' #|'densenet_121'\n",
    "\n",
    "if pretrained_model == 'inception_v3':\n",
    "    base_model=InceptionV3(weights='imagenet',include_top=False, input_shape=(109,91,3)) \n",
    "else:\n",
    "    base_model=DenseNet121(weights='imagenet',include_top=False, input_shape=(109,91,3)) \n",
    "\n",
    "x=base_model.output\n",
    "\n",
    "if use_global_average_pooling == True:\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "else:\n",
    "    x=Flatten()(x)\n",
    "\n",
    "if use_batch_norm:\n",
    "    x = BatchNormalization()(x)\n",
    "if use_drop_out:\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "x = Dense(first_dense_layer_neurons,activation='relu')(x)\n",
    "\n",
    "if use_batch_norm:\n",
    "    x = BatchNormalization()(x)\n",
    "if use_drop_out:\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "x = Dense(second_dense_layer_neurons,activation='relu')(x)\n",
    "\n",
    "if use_batch_norm:\n",
    "    x = BatchNormalization()(x)\n",
    "if use_drop_out:\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "preds = Dense(2,activation='softmax')(x) # final layer with softmax activation\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set up the trainable parameters, fix the pretrained model for now. {display-mode:'form'}\n",
    "optimizer = 'adam' #@param {type:'string'}\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "if optimizer in ['adam', 'adagrad', 'adadelta', 'sgd']: # standard settings\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics = ['accuracy']) # categorical crossentropy would also do...\n",
    "else:\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "trainable_count = int(\n",
    "    np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "non_trainable_count = int(\n",
    "    np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "print('Trainable params: {:,}'.format(trainable_count))\n",
    "print('Non-trainable params: {:,}'.format(non_trainable_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                              epochs=100, # Originally, 500 epochs!\n",
    "                             validation_data=val_generator,\n",
    "                             validation_steps=val_generator.n//val_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Re-write to use MeVisLab test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.evaluate_generator(test_generator, steps=1)\n",
    "predictions = model.predict_generator(test_generator, steps=1)\n",
    "preds = list(zip(predictions[:,0],predictions[:,1]))\n",
    "\n",
    "print(model.metrics_names, model_metrics)\n",
    "\n",
    "result = list(zip(test_generator.filenames, preds))\n",
    "with open('results_InceptionV3_FC-layers_ppmiOnUKEall_300-128-1.txt', 'w') as f:\n",
    "    f.write(repr(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.evaluate_generator(test_generator, steps=1)\n",
    "predictions = model.predict_generator(test_generator, steps=1)\n",
    "preds = list(zip(predictions[:,0],predictions[:,1]))\n",
    "\n",
    "print(model.metrics_names, model_metrics)\n",
    "\n",
    "result = list(zip(test_generator.filenames, preds))\n",
    "with open('results_InceptionV3_FC-layers_ppmiOnUKEall_300-128-1.txt', 'w') as f:\n",
    "    f.write(repr(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second experiment, fine-tuning the inception blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "# from keras.optimizers import SGD\n",
    "# model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history_test = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                              epochs=100,\n",
    "                             validation_data=val_generator,\n",
    "                             validation_steps=val_generator.n//val_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_test.history['loss'], label='train loss')\n",
    "plt.plot(history_test.history['acc'], label='train acc')\n",
    "plt.plot(history_test.history['val_loss'], label='val loss')\n",
    "plt.plot(history_test.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = model.evaluate_generator(test_generator, steps=1)\n",
    "predictions = model.predict_generator(test_generator, steps=1)\n",
    "preds = list(zip(predictions[:,0],predictions[:,1]))\n",
    "\n",
    "print(model.metrics_names, model_metrics)\n",
    "\n",
    "result = list(zip(test_generator.filenames, preds))\n",
    "with open('results_InceptionV3_Inception-layers_ppmiOnUKEall_300-128-1.tx', 'w') as f:\n",
    "    f.write(repr(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
