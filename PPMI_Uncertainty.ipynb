{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI uncertainty quantification\n",
    "\n",
    "_(c) Fraunhofer MEVIS/UKE 2019_\n",
    "\n",
    "This experiment classifies PPMI data with respect to the PD/HC class given. In addition, the data has been visually graded into three classes: certain PD, certain HC, and uncertain.\n",
    "\n",
    "Also, two SBR values are given, calculated with standard methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.0.0-rc0\n",
      "Keras: 2.2.4-tf\n",
      "Have GPU: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "print('TF:', tf.__version__)\n",
    "print('Keras:', tf.keras.__version__)\n",
    "print('Have GPU:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'Z:/Data/Parkinson_DATScans UKE/full_ppmi_data/png/all_2d'\n",
    "PROJECT_ROOT = \"C:/Users/mharz/Documents/Projects/DeepLearning/2019_ParkinsonPPMI-UKE/\"\n",
    "VISUAL_SCORE_CSV = 'PPMI_visual_score_03Oct2019.csv'\n",
    "SBR_CUTOFF_DIST_CSV = 'PPMI_SBR_distance_to_cutoff.csv'\n",
    "SBR_CUTOFF_DIST_MIXED_CSV = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root_path = Path(PROJECT_ROOT)\n",
    "data_root_path = Path(DATA_ROOT)\n",
    "ppmi_df = pd.read_csv(project_root_path / VISUAL_SCORE_CSV)\n",
    "files_df = pd.DataFrame(list(data_root_path.glob('**/*.png')))\n",
    "files_df = files_df.rename(columns={0 : 'fname'})\n",
    "files_df['fname'] = files_df['fname'].apply(lambda path: str(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_for(ID):\n",
    "    c = ppmi_df.loc[ppmi_df['PPMI-ID'] == int(ID)]['group(HC=0,PD=1)'].values[0]\n",
    "    return 'HC' if c==0 else 'PD'\n",
    "\n",
    "def get_visual_result_for(ID):\n",
    "    return ppmi_df.loc[ppmi_df['PPMI-ID'] == int(ID)]['visually(reduced=-1,normal=1,uncertian=0)'].values[0]\n",
    "\n",
    "def get_SBR_HV(ID):\n",
    "    return ppmi_df.loc[ppmi_df['PPMI-ID'] == int(ID)]['putSBR_HV'].values[0]\n",
    "\n",
    "def get_SBR_AAL(ID):\n",
    "    return ppmi_df.loc[ppmi_df['PPMI-ID'] == int(ID)]['putSBR_AAL'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the PPMI ID from the file name\n",
    "files_df['PPMI-ID'] = files_df['fname'].apply(lambda ID: ID.split('_')[-2])\n",
    "# Get class and visual ispection result from ppmi_df\n",
    "files_df['class'] = files_df['PPMI-ID'].apply(lambda ID: get_class_for(ID))\n",
    "files_df['visual_result'] = files_df['PPMI-ID'].apply(lambda ID: get_visual_result_for(ID))\n",
    "files_df['SBR_HV'] = files_df['PPMI-ID'].apply(lambda ID: get_SBR_HV(ID))\n",
    "files_df['SBR_AAL'] = files_df['PPMI-ID'].apply(lambda ID: get_SBR_AAL(ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the groups\n",
    "# We have smoothed and unsmoothed variants of all patients, which cannot end up in train/test/validation separately. Split the data patient-wise instead of file-wise.\n",
    "groups = [df for _, df in files_df.groupby('PPMI-ID')] # Creates a list of dataframes\n",
    "np.random.shuffle(groups)      # Shuffles the dataframes\n",
    "\n",
    "groups_idx = np.arange(len(groups))\n",
    "# Draw train and validation without replacement from the index.\n",
    "train_idx = np.random.choice(groups_idx, int(0.8 * len(groups)), replace=False)\n",
    "val_idx = np.random.choice(list(set(groups_idx) - set(train_idx)), int(0.1 * len(groups)), replace=False)\n",
    "test_idx = np.array(list(set(groups_idx) - set(train_idx) - set(val_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the subset of files per group into new dataframes\n",
    "train_groups = [groups[idx] for idx in train_idx.tolist()]\n",
    "train_df = pd.concat(train_groups).reset_index(drop=True)\n",
    "val_groups = [groups[idx] for idx in val_idx.tolist()]\n",
    "val_df = pd.concat(val_groups).reset_index(drop=True)\n",
    "test_groups = [groups[idx] for idx in test_idx.tolist()]\n",
    "test_df = pd.concat(test_groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1032 validated image filenames belonging to 2 classes.\n",
      "Found 128 validated image filenames belonging to 2 classes.\n",
      "Found 130 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(horizontal_flip=True,\n",
    "                              rescale=1./255.)\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='fname',\n",
    "        y_col='class', # add other columns for more involved models.\n",
    "        class_mode='categorical',\n",
    "        target_size=(109, 91),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_flow(datagen, dataframe):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe, \n",
    "        x_col='fname',\n",
    "        y_col='class', # add other columns for more involved models.\n",
    "        class_mode='categorical',\n",
    "        target_size=(109, 91),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "data_generator = create_datagen()\n",
    "train_gen = create_flow(data_generator, train_df) \n",
    "val_gen = create_flow(data_generator, val_df)\n",
    "test_gen = create_test_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "#base_model = efn.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(109,91,3))\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(109,91,3))\n",
    "\n",
    "# Definition using functional API lets one inspect the layers of the base model.\n",
    "def build_model():\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "#    x = layers.Dense(512,activation='selu')(x) \n",
    "#    x = layers.Dropout(rate=0.3)(x)\n",
    "#    x = layers.Dense(256,activation='selu')(x)\n",
    "#    x = layers.Dropout(rate=0.3)(x)\n",
    "    preds = layers.Dense(2,activation='softmax')(x) \n",
    "\n",
    "    model = Model(inputs=base_model.input,outputs=preds)\n",
    "    return model\n",
    "\n",
    "model = build_model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definition using functional API lets one inspect the layers of the base model.\n",
    "def build_model():\n",
    "    x = layers.Input(shape=(109,91,1))\n",
    "    x = layers.Conv2D(filters=64, activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "#    x = layers.Dense(512,activation='selu')(x) \n",
    "#    x = layers.Dropout(rate=0.3)(x)\n",
    "    x = layers.Dense(256,activation='selu')(x)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "    preds = layers.Dense(2,activation='softmax')(x) \n",
    "\n",
    "    model = Model(inputs=base_model.input,outputs=preds)\n",
    "    return model\n",
    "\n",
    "model = build_model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model_mobilenetv2.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "#tensorboard_cb = tf.keras.callbacks.TensorBoard()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=Path('tb_logs/model_mobilenetv2/'))#, histogram_freq=1, write_grads=True) # Callback does not work on Windows currently (path issues, cf. https://github.com/tensorflow/tensorboard/issues/2279 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_gen.n / BATCH_SIZE,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_gen.n / BATCH_SIZE,\n",
    "    callbacks=[checkpoint],#, tensorboard_cb],\n",
    "    epochs=10,\n",
    "    max_queue_size=4, \n",
    "    workers=4,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "try:\n",
    "    history_df = history_df.append(pd.DataFrame(history.history))\n",
    "except:\n",
    "    history_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['accuracy', 'val_accuracy']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
